import { googleIt } from '@bochilteam/scraper'
import axios from 'axios' 
let handler = async (m, { conn, command, args }) => {
const fetch = (await import('node-fetch')).default
let text = args.join` `
if (!text) return conn.reply(m.chat, '*[â—ğˆğğ…ğâ—] ğ™¸ğ™½ğ™¶ğšğ™´ğš‚ğ™´ ğ™´ğ™» ğšƒğ™´ğš‡ğšƒğ™¾ ğ™¾ ğšƒğ™´ğ™¼ğ™° ğš€ğš„ğ™´ ğ™³ğ™´ğš‚ğ™´ğ™´ ğ™±ğš„ğš‚ğ™²ğ™°ğš*', m)
let url = 'https://busqueda.turbus.cl/Turbusqueda-war/centerzone.jsp?zone=3&idbus=' + encodeURIComponent(text)
let search = await googleIt(text)
let msg = search.articles.map(({ title, url, description }) => { return `*${title}*\n_${url}_\n_${description}_` }).join('\n\n')
try {
let ss = `https://image.thum.io/get/fullpage/${url}`
await conn.sendFile(m.chat, ss, 'error.png', url + '\n\n' + msg, m)
} catch {
m.reply(msg)
}}
handler.help = ['google', 'googlef'].map(v => v + ' <pencarian>')
handler.tags = ['internet']
handler.command = /^googlef?$/i
export default handler

/*let ss2 = await ssweb(url, 'desktop')
let dataa = ss2.result
async function ssweb(url, device = 'desktop'){
return new Promise((resolve, reject) => {
const base = 'https://www.screenshotmachine.com'
const param = { url: url, device: device, cacheLimit: 0 }
axios({url: base + '/capture.php', method: 'POST', data: new URLSearchParams(Object.entries(param)), headers: { 'content-type': 'application/x-www-form-urlencoded; charset=UTF-8' }}).then((data) => {
const cookies = data.headers['set-cookie']
if (data.data.status == 'success') {
axios.get(base + '/' + data.data.link, { headers: { 'cookie': cookies.join('') }, responseType: 'arraybuffer' }).then(({ data }) => {
let result = { status: 200, author: '@BrunoSobrino', result: data } 
resolve(result)})
} else {
reject({ status: 404, author: 'Ryzn', message: data.data })}}).catch(reject)})}*/
var notFond = {
status: link.status,
Pesan: eror}
return notFond}}
let handler = async (m, { conn, text, usedPrefix, command }) => {
if (!text) throw `*[â—ï¸ğˆğğ…ğâ—ï¸] ğ™´ğš‚ğšƒğ™°ğš‚ ğš„ğš‚ğ™°ğ™½ğ™³ğ™¾ ğ™¼ğ™°ğ™» ğ™´ğ™» ğ™²ğ™¾ğ™¼ğ™°ğ™½ğ™³ğ™¾!!*\n*ğš„ğš‚ğ™¾ ğ™²ğ™¾ğšğšğ™´ğ™²ğšƒğ™¾:*\n*${usedPrefix + command} ğ™¿ğšŠğš•ğšŠğš‹ğš›ğšŠ ğšŒğš•ğšŠğšŸğš ğšŠ ğš‹ğšğšœğšŒğšŠğš›*\n\n*ğ™´ğ™¹ğ™´ğ™¼ğ™¿ğ™»ğ™¾:*\n*${usedPrefix + command} Estrellas*`
wikipedia(`${text}`).then(res => {
m.reply(`*ğ™°ğš€ğš„ğ™¸ ğšƒğ™¸ğ™´ğ™½ğ™´ğš‚ ğ™»ğ™° ğ™¸ğ™½ğ™µğ™¾ğšğ™¼ğ™°ğ™²ğ™¸ğ™¾ğ™½ ğ™´ğ™½ğ™²ğ™¾ğ™½ğšƒğšğ™°ğ™³ğ™°:*\n\n` + res.result.isi)
}).catch(() => { m.reply('*[â—ï¸ğˆğğ…ğâ—ï¸] ğ™½ğ™¾ ğš‚ğ™´ ğ™´ğ™½ğ™²ğ™¾ğ™½ğšƒğšğ™¾ ğ™½ğ™¸ğ™½ğ™¶ğš„ğ™½ğ™° ğ™¸ğ™½ğ™µğ™¾ğšğ™¼ğ™°ğ™²ğ™¸ğ™¾ğ™½, ğ™¿ğšğš„ğ™´ğ™±ğ™° ğš€ğš„ğ™´ ğ™·ğ™°ğšˆğ™°ğš‚ ğ™´ğš‚ğ™²ğšğ™¸ğšƒğ™¾ ğš„ğ™½ğ™° ğš‚ğ™¾ğ™»ğ™° ğ™¿ğ™°ğ™»ğ™°ğ™±ğšğ™° ğšˆ ğ™»ğ™¾ ğ™·ğ™°ğšˆğ™°ğš‚ ğ™´ğš‚ğ™²ğšğ™¸ğšƒğ™¾ ğ™²ğ™¾ğšğšğ™´ğ™²ğšƒğ™°ğ™¼ğ™´ğ™½ğšƒğ™´*') })}
handler.help = ['wikipedia'].map(v => v + ' <apa>')
handler.tags = [ 'internet']
handler.command = /^(bus|turbus)$/i
export default handler
